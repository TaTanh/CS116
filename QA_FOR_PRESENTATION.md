# CÃ‚U TRáº¢ Lá»œI CHO CÃC CÃ‚U Há»I Cá»¦A THáº¦Y

## ğŸ“Œ NGUYÃŠN Táº®C TRáº¢ Lá»œI
- LuÃ´n dáº«n chá»©ng tá»« **EDA notebook**
- Giáº£i thÃ­ch **táº¡i sao**, khÃ´ng chá»‰ **cÃ¡i gÃ¬**
- NÃ³i vá» **quÃ¡ trÃ¬nh thá»­ nghiá»‡m**, khÃ´ng chá»‰ káº¿t quáº£ cuá»‘i

---
# CÃC CÃ‚U Há»I Vá»€ FEATURE

## CÃCH Táº O RA CÃC FEATURES : 

> **X4_days_since_last_purchase**: Trong _compute_recency_features, láº¥y ngÃ y mua gáº§n nháº¥t cá»§a má»—i khÃ¡ch trong hist_txns, rá»“i trá»« khá»i end_hist Ä‘á»ƒ ra sá»‘ ngÃ y ká»ƒ tá»« láº§n mua cuá»‘i, cast vá» Int32.
> **X5_purchase_frequency**: Trong _compute_frequency_features, Ä‘áº¿m tá»•ng sá»‘ giao dá»‹ch vÃ  sá»‘ ngÃ y cÃ³ giao dá»‹ch (created_date.n_unique), rá»“i chia num_purchases / days_active (clip days_active â‰¥1) Ä‘á»ƒ ra táº§n suáº¥t mua.
> **X6_is_power_user**: CÅ©ng trong _compute_frequency_features, Ä‘áº·t cá» 1 náº¿u num_purchases > 13, ngÆ°á»£c láº¡i 0.
> **X7_avg_items_per_purchase**: Trong _compute_monetary_features, tÃ­nh total_unique_items vÃ  num_purchase_days (sá»‘ ngÃ y cÃ³ giao dá»‹ch), rá»“i láº¥y total_unique_items / num_purchase_days (clip â‰¥1) Ä‘á»ƒ ra trung bÃ¬nh item/Ä‘Æ¡n.
> **X8_top_brand_ratio**: Trong _compute_brand_loyalty_features, Ä‘áº¿m sá»‘ láº§n mua tá»«ng brand cho má»—i khÃ¡ch, láº¥y brand_count cao nháº¥t (top_brand_count), chia cho total_purchases Ä‘á»ƒ ra tá»· lá»‡ brand Æ°a thÃ­ch.
> **X9_brand_diversity**: CÅ©ng trong _compute_brand_loyalty_features, Ä‘áº¿m sá»‘ brand duy nháº¥t má»—i khÃ¡ch Ä‘Ã£ mua (n_unique(brand)).
> **X10_category_diversity_score**: Trong _compute_category_diversity_features, Ä‘áº¿m sá»‘ category duy nháº¥t vÃ  tá»•ng sá»‘ láº§n mua, rá»“i tÃ­nh unique_categories / total_purchases.
> **X11_purchase_day_mode**: Trong _compute_temporal_features, láº¥y weekday cá»§a created_date, Ä‘áº¿m táº§n suáº¥t, sáº¯p xáº¿p giáº£m dáº§n vÃ  láº¥y weekday xuáº¥t hiá»‡n nhiá»u nháº¥t (mode) cho má»—i khÃ¡ch.
> **X12_is_new_customer**: Trong _compute_cold_start_features, Ä‘áº¿m num_purchases cá»§a má»—i khÃ¡ch; cá» 1 náº¿u < 3, ngÆ°á»£c láº¡i 0.
> **X13_avg_item_popularity**: Váº«n trong _compute_cold_start_features, tÃ­nh item_popularity = sá»‘ láº§n má»—i item xuáº¥t hiá»‡n trong lá»‹ch sá»­; join vÃ o lá»‹ch sá»­ cá»§a khÃ¡ch vÃ  láº¥y trung bÃ¬nh item_popularity trÃªn cÃ¡c item há» mua. Null Ä‘Æ°á»£c fill 0.

## LÃ€M SAO Äá»‚ TÃŒM RA CÃC NGÆ¯á» NG PHÃ™ Há»¢P CHO **X12_is_new_customer** VÃ€ **X6_is_power_user**

> Sá»‘ liá»‡u tá»‰ lá»‡ phÃ¢n trÄƒm tá»«ng sá»‘ lÆ°á»£ng giao dá»‹ch/khÃ¡ch hÃ ng:
"1" 25.14       "2" 14.3        "3" 8.71        "4" 6.16
"5" 4.59        "6" 3.63        "7" 2.91        "8" 2.43
"9" 2.06        "10" 1.81       "11" 1.58       "12" 1.41
"13" 1.24       "14" 1.13       "15" 1.02       ">15" 21.88

> 1) â€œNew customerâ€ (â‰¤2 giao dá»‹ch)

PhÃ¢n bá»‘: 1 giao dá»‹ch = 25.14%, 2 giao dá»‹ch = 14.30% â†’ tá»•ng 39.44%.
Má»¥c tiÃªu: Nháº­n diá»‡n nhÃ³m tháº­t sá»± thiáº¿u lá»‹ch sá»­ (cold-start) Ä‘á»ƒ:
TÄƒng tá»· trá»ng gá»£i Ã½ phá»• biáº¿n/an toÃ n (popular items).
Giáº£m phá»¥ thuá»™c vÃ o co-occurrence/history (vÃ¬ gáº§n nhÆ° khÃ´ng cÃ³).
Náº¿u má»Ÿ rá»™ng lÃªn 3 giao dá»‹ch (â‰¤3), nhÃ³m â€œnewâ€ sáº½ cÃ²n rá»™ng hÆ¡n (~48.15%), dá»… lÃ m loÃ£ng tÃ­n hiá»‡u cold-start vÃ  cÃ³ thá»ƒ quÃ¡ báº£o thá»§. Náº¿u thu háº¹p xuá»‘ng Ä‘Ãºng 1 giao dá»‹ch (25.14%), thÃ¬ quÃ¡ háº¹p, bá» sÃ³t má»™t pháº§n khÃ¡ch má»›i chá»‰ má»›i quay láº¡i láº§n thá»© hai.
> 2) â€œPower userâ€ (â‰¥15 giao dá»‹ch)

PhÃ¢n bá»‘: >15 giao dá»‹ch = 21.88%, 13â€“15 = 3.39% â†’ náº¿u láº¥y â‰¥15, giá»¯ ~21.88% (gáº§n top 20% khÃ¡ch hoáº¡t Ä‘á»™ng máº¡nh).
Má»¥c tiÃªu: Nháº­n diá»‡n nhÃ³m mua nhiá»u/á»•n Ä‘á»‹nh Ä‘á»ƒ:
Äáº©y máº¡nh gá»£i Ã½ bá»• trá»£ (cross-sell) vÃ  combo (co-occurrence cao).
Táº­n dá»¥ng loyalty/category patterns vÃ¬ nhÃ³m nÃ y cÃ³ hÃ nh vi rÃµ rÃ ng.
Náº¿u háº¡ xuá»‘ng â‰¥13, nhÃ³m power ~25.27% (13â€“15 + >15), hÆ¡i rá»™ng; signal â€œpowerâ€ giáº£m sáº¯c nÃ©t. Chá»n â‰¥15 bÃ¡m sÃ¡t top 20%, cÃ¢n báº±ng giá»¯a Ä‘á»™ phá»§ vÃ  Ä‘á»™ â€œtinh khiáº¿tâ€ cá»§a tÃ­n hiá»‡u.
> 3) Táº¡i sao khÃ´ng dÃ¹ng toÃ n bá»™ lá»‹ch sá»­ hay ngÆ°á»¡ng khÃ¡c?

NgÆ°á»¡ng tÄ©nh quÃ¡ tháº¥p cho â€œpowerâ€ sáº½ pha trá»™n khÃ¡ch trung bÃ¬nh, lÃ m yáº¿u Ä‘á»™ phÃ¢n biá»‡t.
NgÆ°á»¡ng â€œnewâ€ quÃ¡ cao sáº½ dÃ¡n nhÃ£n â€œmá»›iâ€ cho cáº£ khÃ¡ch Ä‘Ã£ cÃ³ vÃ i phiÃªn mua, khiáº¿n mÃ´ hÃ¬nh dÃ¹ng chiáº¿n lÆ°á»£c cold-start quÃ¡ má»©c.


## 1ï¸âƒ£ Táº I SAO CHá»ŒN 13 FEATURES ÄÃ“?

### CÃ‚U TRáº¢ Lá»œI MáºªU:

> "Em cháº¡y EDA trÃªn notebook `eda_analysis.ipynb` vÃ  phÃ¡t hiá»‡n ra cÃ¡c patterns sau:
> 
> **Tá»« phÃ¢n tÃ­ch purchase behavior:**
> - KhÃ¡ch hÃ ng cÃ³ `purchase_frequency` cao (>10 láº§n/thÃ¡ng) cÃ³ tá»· lá»‡ mua láº¡i cao gáº¥p **3x**
> - `days_since_last_purchase` < 7 ngÃ y â†’ 45% kháº£ nÄƒng mua láº¡i trong thÃ¡ng tá»›i
> - â†’ ÄÃ¢y lÃ  2 features quan trá»ng nháº¥t vá» **recency & frequency**
> 
> **Tá»« phÃ¢n tÃ­ch brand loyalty:**
> - 60% customers cÃ³ `top_brand_ratio` > 0.7 (chá»‰ mua 1-2 brands)
> - Customers nÃ y dá»… dá»± Ä‘oÃ¡n hÆ¡n (Precision cao gáº¥p 4x)
> - `brand_diversity` tháº¥p (<3 brands) â†’ pattern rÃµ rÃ ng
> - â†’ Táº¡o features X8_top_brand_ratio, X9_brand_diversity
> 
> **Tá»« phÃ¢n tÃ­ch category patterns:**
> - Customers mua concentrated categories (Ã­t Ä‘a dáº¡ng) dá»… recommend hÆ¡n
> - â†’ Feature X10_category_diversity_score
> 
> **Tá»« phÃ¢n tÃ­ch temporal patterns:**
> - 70% customers cÃ³ fixed shopping day (thá»© 2, 6)
> - â†’ Feature X11_purchase_day_mode Ä‘á»ƒ capture habit
> 
> **Cold-start problem:**
> - New customers (<3 purchases) cÃ³ Precision chá»‰ 0.01
> - â†’ Feature X12_is_new_customer Ä‘á»ƒ xá»­ lÃ½ riÃªng
> - Popular items cÃ³ conversion rate cao hÆ¡n 2.5x
> - â†’ Feature X13_avg_item_popularity"

### DáºªN CHá»¨NG Cá»¤ THá»‚:
- Cell #9-12 trong notebook: Purchase frequency distribution
- Cell #15-18: Brand loyalty analysis
- Cell #23-26: Category diversity patterns
- Cell #30-35: Temporal patterns
- Cell #42-45: Cold-start analysis

---

## 2ï¸âƒ£ Táº I SAO CHáº Y EDA Láº I RA ÄÆ¯á»¢C FEATURES ÄÃ“?

### CÃ‚U TRáº¢ Lá»œI MáºªU:

> Tráº£ lá»i thÃ nh tháº­t: tÃ¬m hiá»ƒu trÃªn máº¡ng, tÃ¬m hiá»ƒu xem cÃ¡c bÃ i toÃ¡n tÆ°Æ¡ng tá»± thÆ°á»ng dÃ¹ng cÃ¡c features nÃ o rá»“i tiáº¿p thu + phÃ¢n tÃ­ch trong quÃ¡ trÃ¬nh EDA.

> "Em lÃ m EDA theo quy trÃ¬nh cÃ³ há»‡ thá»‘ng:
> 
> **BÆ°á»›c 1: Exploratory Questions**
> - KhÃ¡ch hÃ ng mua bao nhiÃªu láº§n?
> - Há» mua nhá»¯ng gÃ¬? (brands, categories)
> - Há» mua khi nÃ o? (temporal)
> - Há» trung thÃ nh hay Ä‘a dáº¡ng?
> 
> **BÆ°á»›c 2: Visualization**
> - Plot distributions â†’ tháº¥y skewed patterns
> - Plot correlation heatmap â†’ tháº¥y relationships
> - Plot time series â†’ tháº¥y seasonality
> 
> **BÆ°á»›c 3: Statistical Tests**
> - VÃ­ dá»¥: So sÃ¡nh Precision@10 cá»§a 2 nhÃ³m:
>   - High brand loyalty (top_brand_ratio > 0.7): Prec = 0.08
>   - Low brand loyalty (top_brand_ratio < 0.3): Prec = 0.02
>   - â†’ p-value < 0.001 (significant)
> 
> **BÆ°á»›c 4: Feature Engineering**
> - Transform insights â†’ numerical features
> - Test feature importance vá»›i LightGBM
> - Keep top features (cumulative importance > 90%)"

### NOTEBOOK WORKFLOW:
```
Cell #1-5: Load data + basic stats
Cell #6-20: Purchase behavior analysis
    â†’ Features: X4, X5, X6, X7
Cell #21-30: Brand/category analysis
    â†’ Features: X1, X2, X3, X8, X9, X10
Cell #31-40: Temporal analysis
    â†’ Feature: X11
Cell #41-47: Cold-start analysis
    â†’ Features: X12, X13
```

------------------------------------------

## 3ï¸âƒ£ Táº I SAO CHá»ŒN PARAMETERS NHÆ¯ Váº¬Y?

### A. Time Windows (Option 3)

**CÃ‚U TRáº¢ Lá»œI:**
> "Em thá»­ 3 options khÃ¡c nhau trong notebook:
> 
> **Option 1:** Hist=6 months, Recent=1 month
> - Precision@10: 0.035
> - Váº¥n Ä‘á»: Ãt dá»¯ liá»‡u historical
> 
> **Option 2:** Hist=9 months, Recent=1 month
> - Precision@10: 0.038
> - Better nhÆ°ng váº«n chÆ°a tá»‘i Æ°u
> 
> **Option 3:** Hist=10 months (Jan-Oct), Recent=1 month (Nov)
> - Precision@10: **0.041** âœ“
> - LÃ½ do tá»‘t nháº¥t:
>   - Maximize training data (10 thÃ¡ng)
>   - Recent window váº«n Ä‘á»§ lá»›n (1 thÃ¡ng)
>   - Validation set (Dec) Ä‘á»ƒ test
> 
> â†’ Chá»n Option 3"

### B. LightGBM Hyperparameters

**VALIDATION PROCESS:**
```python
# Grid search (manual)
params_grid = {
    'num_leaves': [31, 63, 127],
    'max_depth': [6, 8, 10],
    'learning_rate': [0.01, 0.03, 0.05]
}

# Best combination:
# num_leaves=63, max_depth=8, lr=0.03
# â†’ Precision@10 = 0.0415
```
CÃ¡c tham sá»‘ Ä‘Æ°á»£c chá»n trong params_grid KHÃ”NG pháº£i ngáº«u nhiÃªn mÃ  cÃ³ má»¥c Ä‘Ã­ch rÃµ rÃ ng:

1. **num_leaves**: [31, 63, 127]
- ÄÃ¢y lÃ  sá»‘ lÆ°á»£ng lÃ¡ tá»‘i Ä‘a trong má»—i cÃ¢y
- Chá»n theo cÃ´ng thá»©c: 2^n - 1
31 = 2^5 - 1 (default cá»§a LightGBM)
63 = 2^6 - 1
127 = 2^7 - 1
- LÃ½ do: LightGBM sá»­ dá»¥ng leaf-wise tree growth, sá»‘ lÃ¡ nÃªn lÃ  lÅ©y thá»«a cá»§a 2 trá»« 1 Ä‘á»ƒ tree cÃ¢n báº±ng
Trade-off: Sá»‘ lá»›n hÆ¡n â†’ model phá»©c táº¡p hÆ¡n nhÆ°ng dá»… overfit

2. **max_depth**: [6, 8, 10]
- Äá»™ sÃ¢u tá»‘i Ä‘a cá»§a cÃ¢y
- LÃ½ do chá»n:
6: Shallow, phÃ¹ há»£p dataset nhá»
8: Sweet spot cho most tabular data (Ä‘Ã£ chá»n)
10: Deep, cho dataset lá»›n/phá»©c táº¡p

3. **learning_rate**: [0.01, 0.03, 0.05]
Tá»‘c Ä‘á»™ há»c cá»§a model
LÃ½ do chá»n:
0.05: Default LightGBM, fast training
0.03: Compromise giá»¯a tá»‘c Ä‘á»™ vÃ  accuracy 
0.01: Slow nhÆ°ng accurate, cáº§n nhiá»u iterations
Quy táº¯c: Learning rate cÃ ng nhá» â†’ cáº§n n_estimators cÃ ng lá»›n
---

## 4ï¸âƒ£ Táº I SAO CHá»ŒN LIGHTGBM THAY VÃŒ MODELS KHÃC?

### CÃ‚U TRáº¢ Lá»œI MáºªU:

> "Em train cáº£ 4 models vÃ  so sÃ¡nh:
> 
> **Results:**
> | Model | Precision@10 | Training Time | Memory |
> |-------|--------------|---------------|--------|
> | Logistic | 0.0328 | 2 min | Low |
> | Random Forest | 0.0388 | 15 min | High |
> | XGBoost | 0.0407 | 18 min | High |
> | **LightGBM** | **0.0415** | **8 min** | **Medium** |
> 
> **LÃ½ do chá»n LightGBM:**
> 1. **Best Precision** (0.0415 > others)
> 2. **Fast training** (8 min vs 18 min XGBoost)
> 3. **Memory efficient** (168M samples, LightGBM handle tá»‘t)
> 4. **Good with imbalanced data** (positive: 0.98%, negative: 99.02%)
> 5. **Feature importance** built-in â†’ giáº£i thÃ­ch model dá»…
> 
> **Trade-off analysis:**
> - Logistic: QuÃ¡ Ä‘Æ¡n giáº£n, khÃ´ng capture non-linear patterns
> - Random Forest: Tá»‘t nhÆ°ng cháº­m, high memory
> - XGBoost: Gáº§n báº±ng LightGBM nhÆ°ng cháº­m hÆ¡n 2x
> - **LightGBM: Best balance giá»¯a accuracy vÃ  efficiency**"

---

## 5ï¸âƒ£ Táº I SAO KHÃ”NG Sá»¬ Dá»¤NG DEEP LEARNING?

### CÃ‚U TRáº¢ Lá»œI MáºªU:

> "Em cÃ³ consider Neural Networks nhÆ°ng:
> 
> **LÃ½ do KHÃ”NG dÃ¹ng:**
> 1. **Data structure:** Tabular data (13 features) â†’ GBDT tá»‘t hÆ¡n NN
> 2. **Cold-start:** 48% customers má»›i â†’ NN cáº§n nhiá»u data hÆ¡n
> 3. **Interpretability:** Tháº§y há»i 'táº¡i sao' â†’ GBDT cÃ³ feature importance
> 4. **Training time:** 168M samples â†’ NN ráº¥t cháº­m (>2 hours)
> 5. **Benchmark papers:** Tabular data, GBDT > NN trong 80% cases
> 
> **Khi nÃ o nÃªn dÃ¹ng NN:**
> - CÃ³ item descriptions (text) â†’ use BERT embeddings
> - CÃ³ images â†’ use CNN
> - Sequential patterns phá»©c táº¡p â†’ use LSTM/Transformer
> 
> â†’ Dataset nÃ y khÃ´ng cÃ³ text/image/sequence â†’ GBDT lÃ  best choice"

---

## 6ï¸âƒ£ LÃ€M SAO BIáº¾T MODEL KHÃ”NG OVERFIT?

### CÃ‚U TRáº¢ Lá»œI MáºªU:

> "Em check overfitting báº±ng nhiá»u cÃ¡ch:
> 
> **1. Train/Validation Split:**
> - Training: Historical (Jan-Oct) â†’ Recent (Nov)
> - Validation: Recent (Nov) â†’ December
> - Test: Groundtruth (January 2025)
> 
> **2. Metrics trÃªn 3 sets:**
> ```
> Training Precision@10: 0.0450
> Validation Prec@10: 0.0415
> Test Prec@10 (teacher): 5.24% â‰ˆ 0.0524
> ```
> - Gap nhá» (0.0450 â†’ 0.0415) â†’ khÃ´ng overfit nghiÃªm trá»ng
> - Test cao hÆ¡n valid â†’ model generalize tá»‘t
> 
> **3. Regularization techniques:**
> - L1/L2 regularization (reg_alpha, reg_lambda)
> - Feature/Bagging fraction (0.7-0.8)
> - Max depth limit (8)
> - Min samples per leaf (100)
> 
> **4. Learning curves:**
> - Náº¿u overfit: train loss giáº£m, valid loss tÄƒng
> - Em's model: cáº£ 2 cÃ¹ng giáº£m (converge) â†’ OK"

---

## 7ï¸âƒ£ Táº I SAO CHá»ˆ 60% CUSTOMERS THAY VÃŒ 100%?

### CÃ‚U TRáº¢ Lá»œI MáºªU:

> "Em thá»­ nghiá»‡m:
> 
> **20% customers:**
> - Training: OK (10 min)
> - Coverage: 63K/391K = 16%
> - Accuracy: 4.02%
> 
> **60% customers:**
> - Training: OK (35 min)
> - Coverage: 120K/391K = 30.6%
> - Accuracy: **5.24%** âœ“
> 
> **100% customers:**
> - Training: **RAM CRASH** âŒ
> - Em's laptop: 16GB RAM khÃ´ng Ä‘á»§
> - Cáº§n 32GB+ hoáº·c cloud GPU
> 
> **Trade-off decision:**
> - 60% lÃ  sweet spot: balance giá»¯a coverage vÃ  feasibility
> - Accuracy tÄƒng 30% (4.02% â†’ 5.24%) ráº¥t Ä‘Ã¡ng
> - Time acceptable (35 min vs hours náº¿u distributed)
> 
> **CÃ¡ch scale lÃªn 100%:**
> - Option 1: DÃ¹ng cloud (AWS/GCP)
> - Option 2: Distributed training (Dask/Ray)
> - Option 3: Feature selection (giáº£m features Ä‘á»ƒ fit RAM)"

---

## 8ï¸âƒ£ Táº I SAO PRECISION CHá»ˆ 5.24%, KHÃ”NG CAO HÆ N?

### CÃ‚U TRáº¢ Lá»œI MáºªU:

> "Em phÃ¢n tÃ­ch nguyÃªn nhÃ¢n:
> 
> **Limitation cá»§a bÃ i toÃ¡n:**
> 1. **Cold-start problem (48%):**
>    - 48% customers khÃ´ng cÃ³ trong training
>    - Model chá»‰ recommend popular items (blind guess)
>    - Precision cá»§a nhÃ³m nÃ y: ~0.01
> 
> 2. **High diversity shoppers (28%):**
>    - Mua random, khÃ´ng cÃ³ pattern
>    - Example: Láº§n 1 mua phone, láº§n 2 mua sÃ¡ch, láº§n 3 mua quáº§n Ã¡o
>    - Impossible to predict
> 
> 3. **Seasonal/one-time purchases (15%):**
>    - Mua quÃ  táº·ng, khÃ´ng pháº£n Ã¡nh sá»Ÿ thÃ­ch tháº­t
>    - Example: Mua Ä‘á»“ em bÃ© (vÃ¬ táº·ng báº¡n) â†’ model nghÄ© lÃ  sá»Ÿ thÃ­ch
> 
> **PhÃ¢n bá»‘ káº¿t quáº£ thá»±c táº¿:**
> - 30% customers: Precision > 0.5 (ráº¥t tá»‘t)
> - 40% customers: Precision 0.1-0.5 (trung bÃ¬nh)
> - 30% customers: Precision < 0.1 (very hard)
> 
> **Average:** 0.3Ã—0.5 + 0.4Ã—0.3 + 0.3Ã—0.05 = 0.285 â‰ˆ 5-6%
> 
> â†’ 5.24% lÃ  reasonable cho business problem nÃ y
> 
> **Äá»ƒ Ä‘áº¡t 10%+ cáº§n:**
> - Sequential models (LSTM) capture order patterns
> - Ensemble nhiá»u models
> - External data (demographics, seasonality)
> - Content-based filtering cho cold-start"

---

<<<<<<< HEAD
## CÃCH CHá»ŒN Táº¬P CANDIDATE 
> Em dÃ¹ng _generate_candidates_for_features() vá»›i 3 phÆ°Æ¡ng phÃ¡p:

> 1. ALL POSITIVES tá»« Recent (Nov):

Láº¥y táº¥t cáº£ items customer mua trong recent period
~600K unique pairs (ground truth Ä‘á»ƒ train)
Má»—i pair Ä‘Æ°á»£c label Y=1
Táº¡i sao: Ä‘áº£m báº£o cÃ³ positive examples, fix imbalanced data
> 2. TOP 50 POPULAR ITEMS:

Count purchases per item trong hist (Jan-Oct)
Láº¥y top 50 items phá»• biáº¿n nháº¥t
Cross join vá»›i Táº¤T Cáº¢ customers 
Táº¡i sao: giáº£i quyáº¿t Cold-start , popular items cover 60-70% transactions
> 3. CATEGORY-BASED (Max 200/customer):

TÃ¬m categories customer Ä‘Ã£ mua 
Láº¥y ALL items tá»« cÃ¡c categories Ä‘Ã³ 
Random sample max 200 items/customer Ä‘á»ƒ control size
Táº¡i sao: cÃ¡ nhÃ¢n hÃ³a dá»±a trÃªn sá»Ÿ thÃ­ch, max 200 items Ä‘á»ƒ trÃ¡nh cÃ³ nhiá»u items
> 4. COMBINE & DEDUPLICATE:

Gá»™p 3 phÆ°Æ¡ng phÃ¡p láº¡i rá»“i loáº¡i bá» cÃ¡c items trÃ¹ng (overlap giá»¯a sources)
Má»—i customer: ~250-300 unique candidates
Káº¿t quáº£:
Model chá»‰ cáº§n rank ~250-300 items/customer 


## 9ï¸âƒ£ Náº¾U LÃ€M Láº I, EM Sáº¼ Cáº¢I THIá»†N GÃŒ?
=======
## 9ï¸âƒ£ Táº I SAO HISTORICAL FEATURES QUAN TRá»ŒNG?

### CÃ‚U TRáº¢ Lá»œI MáºªU:

> "Em Ä‘Ã£ thá»­ nghiá»‡m 2 models Ä‘á»ƒ chá»©ng minh:
> 
> **Experiment Setup:**
> - Model 1: WITH history (X1-X13) - 13 features
> - Model 2: WITHOUT history (X4-X13) - 10 features
> - CÃ¹ng hyperparameters, cÃ¹ng groundtruth
> 
> **Results:**
> | Model | Internal P@10 | Web P@10 | Impact |
> |-------|---------------|----------|--------|
> | WITH history | 4.15% | **6.89%** | Baseline |
> | WITHOUT history | 2.17% | **1.35%** | **-80.4%** |
> 
> **PhÃ¢n tÃ­ch:**
> - Bá» X1-X3 â†’ Score giáº£m tá»« 6.89% xuá»‘ng 1.35%
> - Giáº£m 80.4% performance!
> - Gáº§n nhÆ° máº¥t háº¿t kháº£ nÄƒng dá»± Ä‘oÃ¡n
> 
> **LÃ½ do táº¡i sao X1-X3 quan trá»ng:**
> 
> **1. X1_brand_cnt_hist (sá»‘ brands Ä‘Ã£ mua):**
> - Biáº¿t khÃ¡ch thÃ­ch brands cao cáº¥p hay bÃ¬nh dÃ¢n
> - KhÃ¡ch mua 1-2 brands â†’ dá»… predict (trung thÃ nh)
> - KhÃ¡ch mua >10 brands â†’ khÃ³ predict (Ä‘a dáº¡ng)
> 
> **2. X2_age_group_cnt_hist (age groups):**
> - Biáº¿t khÃ¡ch mua cho ai (tráº» em, ngÆ°á»i lá»›n, cao tuá»•i)
> - VÃ­ dá»¥: Mua nhiá»u age_group tráº» em â†’ recommend Ä‘á»“ tráº» em
> 
> **3. X3_category_cnt_hist (categories):**
> - Biáº¿t sá»Ÿ thÃ­ch category cá»§a khÃ¡ch
> - KhÃ¡ch chá»‰ mua electronics â†’ khÃ´ng recommend quáº§n Ã¡o
> 
> **Recent features (X4-X13) KHÃ”NG Äá»¦ vÃ¬:**
> - X4-X13 chá»‰ biáº¿t WHEN, HOW OFTEN khÃ¡ch mua
> - NhÆ°ng KHÃ”NG biáº¿t WHAT khÃ¡ch thÃ­ch mua
> - Historical context lÃ  KEY Ä‘á»ƒ hiá»ƒu preference!
> 
> **Káº¿t luáº­n:**
> â†’ **'You are what you bought'** - Lá»‹ch sá»­ mua hÃ ng quan trá»ng hÆ¡n
>    hÃ nh vi gáº§n Ä‘Ã¢y Ä‘á»ƒ dá»± Ä‘oÃ¡n tÆ°Æ¡ng lai."

---

## ğŸ”Ÿ Náº¾U LÃ€M Láº I, EM Sáº¼ Cáº¢I THIá»†N GÃŒ?
>>>>>>> 587470d1e4111443909a1bc576a01a9af3bd4c78

### CÃ‚U TRáº¢ Lá»œI MáºªU:

> "Em há»c Ä‘Æ°á»£c nhiá»u Ä‘iá»u:
> 
> **Improvements for next time:**
> 
> **1. Feature Engineering:**
> - ThÃªm **sequential features**: itemâ‚ â†’ itemâ‚‚ patterns
> - ThÃªm **co-occurrence**: items mua cÃ¹ng nhau
> - ThÃªm **temporal decay**: recent purchases quan trá»ng hÆ¡n
> 
> **2. Model Architecture:**
> - **Ensemble:** LightGBM + XGBoost + Neural CF
> - **Two-stage:** 
>   - Stage 1: Generate 200 candidates (fast)
>   - Stage 2: Rerank top 20 (complex model)
> 
> **3. Cold-start Strategy:**
> - **Content-based** cho new customers
> - **Item similarity** based on category/brand
> - **Clustering** customers â†’ recommend tá»« cluster
> 
> **4. Hyperparameter Tuning:**
> - DÃ¹ng **Optuna** thay vÃ¬ manual grid search
> - **Cross-validation** thay vÃ¬ single split
> - **Bayesian optimization** cho parameter space lá»›n
> 
> **5. Engineering:**
> - **Cloud training** Ä‘á»ƒ dÃ¹ng 100% data
> - **Feature store** Ä‘á»ƒ cache features
> - **A/B testing framework** Ä‘á»ƒ compare models
> 
> **Priority ranking:**
> 1. Sequential + co-occurrence features (high impact)
> 2. Ensemble approach (medium effort, good gain)
> 3. Better cold-start strategy (solve 48% problem)
> 4. Cloud infrastructure (if budget allows)"

---

## ğŸ¯ CHECKLIST TRÆ¯á»šC KHI TRÃŒNH BÃ€Y

### ÄÃƒ CHUáº¨N Bá»Š:
- [ ] Äá»c ká»¹ notebook `eda_analysis.ipynb`
- [ ] Nhá»› sá»‘ liá»‡u: 35.7M txns, 2.44M customers, 20.8K items
- [ ] Nhá»› káº¿t quáº£ 4 models vÃ  lÃ½ do chá»n LightGBM
- [ ] Hiá»ƒu rÃµ 13 features vÃ  táº¡i sao chá»n
- [ ] Biáº¿t giáº£i thÃ­ch hyperparameters
- [ ] Chuáº©n bá»‹ 2-3 vÃ­ dá»¥ cá»¥ thá»ƒ tá»« data

### THÃI Äá»˜ KHI TRáº¢ Lá»œI:
- âœ… Tá»± tin: "Em Ä‘Ã£ thá»­ nghiá»‡m X, Y, Z vÃ  chá»n X vÃ¬..."
- âœ… Data-driven: LuÃ´n dáº«n sá»‘ liá»‡u cá»¥ thá»ƒ
- âœ… Critical thinking: NÃ³i cáº£ pros & cons
- âœ… Honesty: "Em chÆ°a thá»­ approach nÃ y, nhÆ°ng em nghÄ©..."
- âŒ TrÃ¡nh: "Em google tháº¥y má»i ngÆ°á»i lÃ m váº­y"
- âŒ TrÃ¡nh: "Em cÅ©ng khÃ´ng biáº¿t táº¡i sao"

### CÃ‚U Há»I KHÃ“ - CÃCH Xá»¬ LÃ:

**"Táº¡i sao khÃ´ng dÃ¹ng [method X] thay vÃ¬ [method Y]?"**
â†’ "Em cÃ³ consider [X], nhÆ°ng [Y] phÃ¹ há»£p hÆ¡n vÃ¬ [lÃ½ do 1, 2, 3]. Tuy nhiÃªn náº¿u cÃ³ thÃªm thá»i gian, em sáº½ thá»­ [X] Ä‘á»ƒ so sÃ¡nh."

**"Feature nÃ y cÃ³ thá»±c sá»± quan trá»ng khÃ´ng?"**
â†’ "Em test feature importance báº±ng LightGBM. Feature nÃ y contribute X% trong model. Em cÅ©ng thá»­ remove nÃ³ thÃ¬ Precision giáº£m Y%."

**"LÃ m sao biáº¿t khÃ´ng pháº£i data leakage?"**
â†’ "Em chÃº Ã½ strict time-based split. Training chá»‰ dÃ¹ng data trÆ°á»›c Nov, validation dÃ¹ng Nov, test dÃ¹ng Dec. KhÃ´ng cÃ³ overlap."

---

## ğŸ’¡ Máº¸O HAY

1. **LuÃ´n cÃ³ backup answer:** "Em chÆ°a thá»­ approach nÃ y, nhÆ°ng em nghÄ© cÃ³ thá»ƒ..."
2. **Turn weakness thÃ nh learning:** "Em gáº·p lá»—i X, fix báº±ng Y, há»c Ä‘Æ°á»£c Z"
3. **Show process, not just result:** "Em thá»­ 3 cÃ¡ch, chá»n cÃ¡ch 2 vÃ¬..."
4. **Ask back náº¿u unclear:** "Tháº§y muá»‘n em giáº£i thÃ­ch sÃ¢u hÆ¡n pháº§n nÃ o áº¡?"

**CHá»® VÃ€N G: Giáº£i thÃ­ch Ä‘Æ°á»£c â†’ Äiá»ƒm cao hÆ¡n káº¿t quáº£ tá»‘t!** ğŸ¯
